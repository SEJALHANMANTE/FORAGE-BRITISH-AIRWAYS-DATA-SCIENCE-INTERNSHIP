{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e68a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f37c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sejal\n",
      "[nltk_data]     Hanmante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5c74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Sejal Hanmante\\Downloads\\dataBA_reviews1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9dd688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srno</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>✅ Trip Verified |  I was flying to Warsaw for ...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5</td>\n",
       "      <td>3rd December 2022</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>✅ Trip Verified |  Booked a BA holiday to Marr...</td>\n",
       "      <td>1</td>\n",
       "      <td>30th November 2022</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>✅ Trip Verified | Extremely sub-par service. H...</td>\n",
       "      <td>9</td>\n",
       "      <td>28th November 2022</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>✅ Trip Verified |  I virtually gave up on Brit...</td>\n",
       "      <td>2</td>\n",
       "      <td>26th November 2022</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>✅ Trip Verified |  I was pleasantly surprised ...</td>\n",
       "      <td>7</td>\n",
       "      <td>25th November 2022</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16603</th>\n",
       "      <td>16603</td>\n",
       "      <td>LHR-JFK-LAX-LHR. Check in was ok apart from be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29th August 2012</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16604</th>\n",
       "      <td>16604</td>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28th August 2012</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16605</th>\n",
       "      <td>16605</td>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12th October 2011</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16606</th>\n",
       "      <td>16606</td>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11th October 2011</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16607</th>\n",
       "      <td>16607</td>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9th October 2011</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16608 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Srno                                            reviews  \\\n",
       "0          0  ✅ Trip Verified |  I was flying to Warsaw for ...   \n",
       "1          1  ✅ Trip Verified |  Booked a BA holiday to Marr...   \n",
       "2          2  ✅ Trip Verified | Extremely sub-par service. H...   \n",
       "3          3  ✅ Trip Verified |  I virtually gave up on Brit...   \n",
       "4          4  ✅ Trip Verified |  I was pleasantly surprised ...   \n",
       "...      ...                                                ...   \n",
       "16603  16603  LHR-JFK-LAX-LHR. Check in was ok apart from be...   \n",
       "16604  16604  LHR to HAM. Purser addresses all club passenge...   \n",
       "16605  16605  My son who had worked for British Airways urge...   \n",
       "16606  16606  London City-New York JFK via Shannon on A318 b...   \n",
       "16607  16607  SIN-LHR BA12 B747-436 First Class. Old aircraf...   \n",
       "\n",
       "                               stars                date         country  \n",
       "0      \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5   3rd December 2022   United States  \n",
       "1                                  1  30th November 2022  United Kingdom  \n",
       "2                                  9  28th November 2022   United States  \n",
       "3                                  2  26th November 2022  United Kingdom  \n",
       "4                                  7  25th November 2022          Canada  \n",
       "...                              ...                 ...             ...  \n",
       "16603                            NaN    29th August 2012  United Kingdom  \n",
       "16604                            NaN    28th August 2012  United Kingdom  \n",
       "16605                            NaN   12th October 2011  United Kingdom  \n",
       "16606                            NaN   11th October 2011   United States  \n",
       "16607                            NaN    9th October 2011  United Kingdom  \n",
       "\n",
       "[16608 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c00c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6128703c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "16603    False\n",
       "16604    False\n",
       "16605    False\n",
       "16606    False\n",
       "16607    False\n",
       "Name: verified, Length: 16608, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified'] = df.reviews.str.contains(\"Trip Verified\")\n",
    "df['verified']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ed1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for lemmatization of words we will use nltk library\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "reviews_data = df.reviews.str.strip(\"✅ Trip Verified |\")\n",
    "\n",
    "#create an empty list to collect cleaned data corpus\n",
    "corpus =[]\n",
    "\n",
    "#loop through each review, remove punctuations, small case it, join it and add it to corpus\n",
    "for rev in reviews_data:\n",
    "    rev = re.sub('[^a-zA-Z]',' ', rev)\n",
    "    rev = rev.lower()\n",
    "    rev = rev.split()\n",
    "    rev = [lemma.lemmatize(word) for word in rev if word not in set(stopwords.words(\"english\"))]\n",
    "    rev = \" \".join(rev)\n",
    "    corpus.append(rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the corpus to the original dataframe\n",
    "\n",
    "df['corpus'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b572e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6426d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the date to datetime format\n",
    "\n",
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c035b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check for unique values\n",
    "df.stars.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \\t and \\n from the ratings\n",
    "df.stars = df.stars.str.strip(\"\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09879131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop the rows where the value of ratings is None\n",
    "df.drop(df[df.stars == \"None\"].index, axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43269f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop the rows using index where the country value is null\n",
    "df.drop(df[df.country.isnull() == True].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e693720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#resetting the index\n",
    "df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned data\n",
    "\n",
    "df.to_csv(\"C:\\Users\\Sejal Hanmante\\Downloads\\data\\cleanedreviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d0706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
